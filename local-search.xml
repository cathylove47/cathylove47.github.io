<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>论文的一些前置问题</title>
    <link href="/2025/11/21/%E8%AE%BA%E6%96%87%E7%9A%84%E4%B8%80%E4%BA%9B%E5%89%8D%E7%BD%AE%E9%97%AE%E9%A2%98/"/>
    <url>/2025/11/21/%E8%AE%BA%E6%96%87%E7%9A%84%E4%B8%80%E4%BA%9B%E5%89%8D%E7%BD%AE%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h1><p>MEDGS利用了VEGAS（Gaussian Splatting 的变体）在短轴图像上进行了插值，<br>这算是一个不错的baseline<br>接下来我介绍一下medgs的来源，并且提出新的改进目标</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="vegas"><a href="#vegas" class="headerlink" title="vegas"></a>vegas</h3><p>普通的 3DGS 是把 $x, y, z$ 三维空间里的物体变成高斯球。<br>而 <strong>VeGaS</strong> 处理的是一段 2D 视频。视频本来是 $(x, y)$ 的图像随时间 $t$ 变化。</p><p>VeGaS 做了一个很有趣的转换：</p><ul><li>它把视频看作一个 <strong>3D 空间-时间体积 (Space-Time Volume)</strong>。</li><li><strong>X 轴 &amp; Y 轴</strong>：还是图像的宽和高。</li><li><strong>Z 轴</strong>：变成了<strong>时间 (Time)</strong>。</li></ul><h4 id="vegas解决的痛点"><a href="#vegas解决的痛点" class="headerlink" title="vegas解决的痛点"></a>vegas解决的痛点</h4><p>如果只是简单地把视频叠成 3D 空间，用普通的 3D 高斯球去拟合，会遇到一个大问题：<strong>动作通常不是直线的。</strong></p><ul><li><strong>普通高斯球的局限：</strong> 标准的 3D 高斯球是椭球体，它的形状是线性的（直的）。</li><li><strong>视频里的问题：</strong> 比如视频里一个人在挥手，手的轨迹是<strong>弧线</strong>。如果你用一个长长的直条形椭球去代表这只手在几秒内的轨迹，它根本对不上（手是弯着动的，球是直的）。</li><li><strong>之前的笨办法：</strong> 之前的算法（如 VGR）只能把手切成无数个极短的小球，或者强行用变形场去扭，效果不好且难以编辑。</li></ul><p><strong>折叠高斯的引入</strong><br>为了解决“动作是弯的，球是直的”这个问题，作者发明了一种新的数学工具——<strong>Folded-Gaussian Distribution（折叠高斯分布）</strong>。</p><ul><li><strong>原理：</strong> 这种新型高斯球不再是死板的椭球。它引入了一个多项式函数，允许高斯球在“时间轴”方向上发生<strong>非线性的弯曲</strong>。</li><li><strong>通俗理解：</strong> 想象你有一根这就好比一根直香肠（普通高斯），现在你可以把它<strong>掰弯</strong>（Folded Gaussian），让它完美贴合视频里那个挥手动作的弧线轨迹。</li><li><strong>条件概率：</strong> 当我们需要渲染某一帧（比如第 5 秒）时，VeGaS 会在这个弯曲的高斯管上“切一刀”（Conditioning），切出来的截面就是一个 2D 的高斯斑点，正好对应那一帧图像里的物体。</li></ul><p>具体的输入输出：</p><ol><li><strong>输入：</strong> 一段普通的 2D 视频（不需要多视角，就普通手机拍的视频）。</li><li><strong>初始化：</strong> 在这个“视频立方体”里撒入 3D 高斯球。</li><li><strong>优化：</strong><ul><li>调整这些球的位置、颜色。</li><li><strong>关键：</strong> 调整“折叠参数”，让高斯球弯曲，去追踪视频里物体的运动轨迹。</li><li>利用对比原始视频帧的 Loss 来更新参数。</li></ul></li></ol><h3 id="medgs是如何借鉴vegas的"><a href="#medgs是如何借鉴vegas的" class="headerlink" title="medgs是如何借鉴vegas的"></a>medgs是如何借鉴vegas的</h3><p>VeGaS 的核心是处理 $(x, y, t)$，而 MRI 数据是 $(x, y, z)$。</p><ul><li><strong>在 VeGaS 中：</strong> 第 3 维度是<strong>时间</strong>。第 1 帧和第 2 帧之间，代表物体“动”了一点点。</li><li><strong>在 MedGS 中：</strong> 第 3 维度是<strong>深度（层）</strong>。第 1 张切片和第 2 张切片之间，代表人体组织结构“变”了一点点。</li></ul><p><strong>魔改的第一步</strong>就是直接把 MRI 的第 $i$ 张切片，当成视频的第 $i$ 帧喂给网络。网络以为它在学一个“变形的动画”，其实它在学一个“静态的 3D 结构”。</p><p>渲染方式的魔改：从“拍照”变成“切片”</p><p>这是最关键的区别。普通的 3DGS（包括 VeGaS）是模拟<strong>摄像机（Camera）</strong>，有近大远小的透视效果。但 MRI 不需要透视。</p><p>MedGS 对渲染管线做了如下修改：</p><ul><li><strong>原版 VeGaS&#x2F;3DGS：</strong><ul><li>我在 3D 空间放一个摄像机。</li><li>把高斯球投影到屏幕上（Perspective Projection）。</li><li>计算颜色叠加。</li></ul></li><li><strong>魔改后的 MedGS：</strong><ul><li><strong>正交投影 (Orthographic Projection)：</strong> 取消“近大远小”，模拟医学扫描仪的射线平行穿过。</li><li><strong>条件切片 (Conditional Slicing)：</strong><br>当训练第 5 张 PNG（假设它对应 $z&#x3D;10mm$ 处）时，算法<strong>只激活</strong>和渲染 z 轴坐标在 $10mm$ 附近的高斯球。<br>它就像一把<strong>数字手术刀</strong>，只横切这一层，计算这一层截面的颜色，然后跟第 5 张 PNG 去算 Loss。</li></ul></li></ul><blockquote><p>因为MRI是只有20层，这在医学上属于稀疏采样，如果直接堆叠，层与层之间会有间隙，这会导致信息丢失。所以medgs利用了vegas的折叠高斯分布，在层与层之间进行插值，实现了超分辨率</p></blockquote><h4 id="为什么3dgs能够应用于心脏MRI插值，对比线性插值"><a href="#为什么3dgs能够应用于心脏MRI插值，对比线性插值" class="headerlink" title="为什么3dgs能够应用于心脏MRI插值，对比线性插值"></a>为什么3dgs能够应用于心脏MRI插值，对比线性插值</h4><table><thead><tr><th align="left">对比维度</th><th align="left">线性插值 (Linear Interpolation)</th><th align="left">3DGS &#x2F; MedGS</th></tr></thead><tbody><tr><td align="left"><strong>处理逻辑</strong></td><td align="left">纯数学计算，像素对像素混合</td><td align="left">几何拟合，用 3D 形状去逼近数据</td></tr><tr><td align="left"><strong>斜向物体</strong></td><td align="left">产生重影 (Ghosting)，结构断裂</td><td align="left"><strong>自动对齐</strong>，保持管状&#x2F;块状连续性</td></tr><tr><td align="left"><strong>层间空隙</strong></td><td align="left">模糊过渡，丢失细节</td><td align="left"><strong>利用椭球体积填充</strong>，保持边缘清晰</td></tr><tr><td align="left"><strong>数据依赖</strong></td><td align="left">极度依赖采样率，层距大就完蛋</td><td align="left">对稀疏数据鲁棒性更强（能脑补）</td></tr></tbody></table><p><strong>结论：</strong><br>如果你的 MRI 切片非常密集（比如 z 轴分辨率极高），线性插值够快也够用。<br>但正如你所说，只有 <strong>20 张切片</strong>（稀疏数据），线性插值会导致严重的<strong>层间断裂</strong>和<strong>阶梯效应</strong>。这时候，3DGS 利用其<strong>几何连续性</strong>的特性，能“猜”出比线性插值更符合人体生理结构的中间层。</p><p>它不是在瞎猜，它是假设“人体是连续的 3D 实体”来进行拟合，这在医学上是一个非常合理的假设。</p><h2 id="我的一些想法"><a href="#我的一些想法" class="headerlink" title="我的一些想法"></a>我的一些想法</h2><ol><li>引入长轴LAX图像作为硬性几何约束</li><li>引入扩散模型，指导3dgs的拟合</li><li>时间维度的引导，比如T0时刻的第五层，可能因为心脏运动变成了T1时刻的第六层？（猜想）</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文的构思</title>
    <link href="/2025/11/19/%E8%AE%BA%E6%96%87%E7%9A%84%E6%9E%84%E6%80%9D/"/>
    <url>/2025/11/19/%E8%AE%BA%E6%96%87%E7%9A%84%E6%9E%84%E6%80%9D/</url>
    
    <content type="html"><![CDATA[<p>这是一个非常棒的研究切入点！心脏 MRI 重建（Cardiac MRI Reconstruction）一直是 <strong>MICCAI</strong>（医学影像顶会）的热门赛道。</p><p>你目前的做法是“利用 VEGAS（Gaussian Splatting 的变体）做短轴（SAX）切片的 Z 轴插值&#x2F;超分”。这算是一个不错的 <strong>Baseline</strong>。</p><p>为了发一篇高质量的论文，单纯的插值确实不够，<strong>引入“长轴（LAX）监督”和“扩散模型（Diffusion Prior）”绝对是两个非常有价值的加分项</strong>。</p><p>我们可以把你的工作包装成一个**“多视角一致性 + 生成式先验辅助的 4D 心脏高保真重建”**系统。</p><p>以下我为你构思的三个具体的创新点方案，你可以根据实现的难易程度选择：</p><hr><h3 id="创新点一：引入长轴（LAX）作为“硬几何约束”-Geometric-Constraint"><a href="#创新点一：引入长轴（LAX）作为“硬几何约束”-Geometric-Constraint" class="headerlink" title="创新点一：引入长轴（LAX）作为“硬几何约束” (Geometric Constraint)"></a>创新点一：引入长轴（LAX）作为“硬几何约束” (Geometric Constraint)</h3><p><strong>核心逻辑：</strong> 短轴（SAX）切片虽然多（20张），但在 Z 轴依然是稀疏的。而长轴（LAX）切片虽然少（5张），但它们在空间上与 SAX 是<strong>正交或呈一定角度</strong>的。<br><strong>价值：</strong> 利用 LAX 数据不仅仅是“辅助”，而是构建**“多视角一致性（Cross-view Consistency）”**。这是 3DGS 的强项。</p><ul><li><strong>怎么做（How）：</strong><ol><li><strong>统一坐标系</strong>：首先利用 DICOM 头文件里的位置信息，将 SAX 和 LAX 的切片统一转换到同一个世界坐标系下。</li><li><strong>联合训练</strong>：不要只用 SAX 训练 Gaussian。在训练时，随机采样视角，既包括 SAX 的视角，也包括 LAX 的视角。</li><li><strong>相交区域约束</strong>：在 SAX 和 LAX 图像在空间中相交的区域（Intersection Line），它们的像素值（MRI 强度）理论上应该是一样的。<ul><li>你可以设计一个 <strong>Intersection Loss</strong>：强制 3DGS 在渲染这两个不同视角时，在相交线上的预测值保持一致。</li></ul></li><li><strong>效果</strong>：LAX 切片会像“钉子”一样，把 SAX 插值产生的模糊 Z 轴结构“钉实”，修正心脏壁的几何形状，防止插值出现变形。</li></ol></li></ul><h3 id="创新点二：引入扩散模型作为“软解剖先验”-Anatomical-Prior"><a href="#创新点二：引入扩散模型作为“软解剖先验”-Anatomical-Prior" class="headerlink" title="创新点二：引入扩散模型作为“软解剖先验” (Anatomical Prior)"></a>创新点二：引入扩散模型作为“软解剖先验” (Anatomical Prior)</h3><p><strong>核心逻辑：</strong> 3DGS 善于拟合数据，但在没有数据的空隙（Z轴间隙），它可能会产生伪影。扩散模型（Diffusion Model）“看过”成千上万张心脏 MRI，它知道正常的心脏肌肉纹理是什么样的。<br><strong>价值：</strong> 这是你提到的“Generative”，用于解决<strong>Ill-posed（病态）问题</strong>，即填补缺失的高频细节。</p><ul><li><strong>怎么做（How）：</strong><ul><li><strong>方案 A（2D 先验指导 3D）：</strong> 类似于 <strong>Score Distillation Sampling (SDS)</strong> 的思路，但不需要文本引导。<ol><li>训练一个无条件（Unconditional）或以切片位置为条件的 2D 心脏 MRI Diffusion 模型。</li><li>在优化 3DGS 时，渲染出一个<strong>未见过的切片位置</strong>（插值位置）。</li><li>把这张渲染图喂给 Diffusion 模型，加噪去噪，计算梯度，告诉 3DGS：“你这里生成的纹理不像真实的心脏组织，改一下”。</li></ol></li><li><strong>方案 B（生成伪切片）：</strong> 这是一个更稳妥的“两阶段”方法。<ol><li>先利用 Diffusion 模型（如基于 Latent Diffusion 的 Inpainting 模型），根据相邻的 SAX 切片，<strong>生成</strong>中间缺失的切片。</li><li>将这些生成的切片作为**伪标签（Pseudo-ground truth）**加入到 3DGS 的训练集中。</li><li>这样 3DGS 就不需要自己瞎猜，而是去拟合 Diffusion 生成的高质量解剖结构。</li></ol></li></ul></li></ul><h3 id="创新点三：利用时间维度（Time）做“时空联合超分”-Spatiotemporal-Super-resolution"><a href="#创新点三：利用时间维度（Time）做“时空联合超分”-Spatiotemporal-Super-resolution" class="headerlink" title="创新点三：利用时间维度（Time）做“时空联合超分” (Spatiotemporal Super-resolution)"></a>创新点三：利用时间维度（Time）做“时空联合超分” (Spatiotemporal Super-resolution)</h3><p><strong>核心逻辑：</strong> 你提到数据带有<strong>时间维度</strong>。心脏在跳动，T0 时刻的第 5 层切片，可能在 T1 时刻心脏收缩后，对应的是 T0 时刻第 5.5 层的解剖结构。<br><strong>价值：</strong> 利用运动信息，让不同时间点的信息互补。</p><ul><li><strong>怎么做（How）：</strong><ul><li>使用 <strong>Deformable 3DGS（可变形高斯）</strong>。</li><li>不要对每个时间点单独建模。建立一个<strong>Canonical Space（标准空间）</strong>（比如舒张末期），然后学习一个**变形场（Deformation Field）**来表示心脏的跳动。</li><li><strong>创新点</strong>：当 Gaussian 随时间移动时，它们会“扫过”原本没有数据的空隙。利用这种<strong>时空相关性</strong>，T1 时刻的数据可以帮助重建 T0 时刻缺失的 Z 轴信息。</li></ul></li></ul><hr><h3 id="💡-综合建议：如何组合成一篇好论文？"><a href="#💡-综合建议：如何组合成一篇好论文？" class="headerlink" title="💡 综合建议：如何组合成一篇好论文？"></a>💡 综合建议：如何组合成一篇好论文？</h3><p>我建议你采用 <strong>“3DGS + LAX Constraint + Diffusion Refinement”</strong> 的组合拳。</p><p><strong>论文 Storyline (故事线) 参考：</strong></p><ol><li><strong>Problem</strong>: 现有的心脏 MRI Z轴分辨率低，传统插值模糊，且单纯的生成模型缺乏 3D 一致性。</li><li><strong>Method (你的模型名字，比如 HeartGaussian)</strong>:<ul><li><strong>Base</strong>: 使用 <strong>Deformable 3DGS</strong> 建模动态心脏（利用了时间维度）。</li><li><strong>Contribution 1 (几何)</strong>: 提出 <strong>“Orthogonal Plane Guidance” (正交平面引导)</strong>，利用 5 张 LAX 切片作为稀疏视角监督，锁定心脏的整体几何结构。</li><li><strong>Contribution 2 (纹理)</strong>: 引入 <strong>“Diffusion-based Slice Refinement”</strong>，利用预训练的 2D Diffusion 模型作为正则化项，优化插值区域的纹理细节，使其符合解剖学特征。</li></ul></li><li><strong>Result</strong>: 相比于单纯的插值（Bicubic&#x2F;Spline）和单纯的 3DGS（Vegas），你的方法在 PSNR 上更高（因为有 LAX 修正），且在 LPIPS（感知指标）上更好（因为有 Diffusion 加持）。</li></ol><p><strong>总结：</strong><br>你的想法完全可行！<strong>长轴监督</strong>是必须加的（因为它就在你手里，不用白不用，且非常符合 3DGS 的多视角特性）。<strong>扩散模型</strong>可以作为一个提升画质的模块加入，这样你的论文既有传统的几何约束（Rigorous），又有生成式 AI 的前沿技术（Fancy），非常适合投 MICCAI 或 IEEE TMI。</p><hr><p>这是两个非常具体且关键的问题。只要解决了这两个顾虑，你的论文逻辑就通了。</p><p>我来分两部分回答你：一是<strong>长短轴结合的“含金量”与潜在坑点</strong>，二是<strong>针对你目前的背景，最高效的扩散模型（Diffusion）上手路线</strong>。</p><hr><h3 id="第一部分：长轴（LAX）监督到底强不强？"><a href="#第一部分：长轴（LAX）监督到底强不强？" class="headerlink" title="第一部分：长轴（LAX）监督到底强不强？"></a>第一部分：长轴（LAX）监督到底强不强？</h3><p><strong>结论：非常强，而且是医学影像重建里的“黄金标准”。但有一个前提——配准（Registration）。</strong></p><h4 id="1-为什么强？（从几何角度看）"><a href="#1-为什么强？（从几何角度看）" class="headerlink" title="1. 为什么强？（从几何角度看）"></a>1. 为什么强？（从几何角度看）</h4><p>想象你在切一块面包（心脏）。</p><ul><li><strong>SAX（短轴）</strong>：是你横着切了 20 刀，每一片面包内部很清晰，但两片面包之间（Z轴）是空的，或者是你插值“猜”出来的。</li><li><strong>LAX（长轴）</strong>：是你竖着切了 5 刀。</li><li><strong>关键点</strong>：这 5 刀竖着切下去，会<strong>垂直穿过</strong>你所有的 20 片横切面。</li><li><strong>监督信号</strong>：在长轴和短轴的<strong>交界线</strong>上，像素值必须相等。<ul><li>如果不加长轴：你的插值可能是“平滑但错误”的。</li><li>加了长轴：这 5 个面就像 5 根钢筋，把松散的 SAX 切片“串”起来了。它直接约束了心脏壁在 Z 轴方向的曲率。对于 20 张 SAX 来说，5 张 LAX 提供的交叉约束已经非常密集了。</li></ul></li></ul><h4 id="2-难点与创新机会（Paper的卖点）"><a href="#2-难点与创新机会（Paper的卖点）" class="headerlink" title="2. 难点与创新机会（Paper的卖点）"></a>2. 难点与创新机会（Paper的卖点）</h4><p>你担心的“不强”，通常是因为**“对不齐”**。</p><ul><li><strong>问题</strong>：MRI 扫描 SAX 和 LAX 通常是分次扫描的。病人可能会呼吸、移动，或者心跳周期没完全对上。这会导致 SAX 和 LAX 在空间上对应不起来（比如长轴显示这里是血池，短轴对应位置却是心肌）。</li><li><strong>如果直接强行监督</strong>：模型会糊，因为它不知道该听谁的。</li><li><strong>你的创新点（Contribution）</strong>：<ul><li><strong>不要假设它们是对齐的</strong>。</li><li>在 3DGS 的训练过程中，加入一个**微小的位姿优化（Pose Refinement）**模块。让 Gaussian 在训练几何结构的同时，自动微调 LAX 切片的 6DoF（位置和旋转），使其与 SAX 数据最吻合。</li><li><strong>写法</strong>：这叫 <em>“Joint Optimization of Geometry and Slice Misalignment”</em>（几何与切片错位的联合优化）。这比单纯用数据监督高级得多，是 MICCAI 很喜欢的点。</li></ul></li></ul><hr><h3 id="第二部分：零基础如何快速上手-Diffusion-并结合到你的论文？"><a href="#第二部分：零基础如何快速上手-Diffusion-并结合到你的论文？" class="headerlink" title="第二部分：零基础如何快速上手 Diffusion 并结合到你的论文？"></a>第二部分：零基础如何快速上手 Diffusion 并结合到你的论文？</h3><p>既然你是为了发论文，<strong>不要去学深奥的数学推导</strong>（什么变分下界、马尔可夫链先放一边）。你需要的是**“能跑通，能生成图，能当正则项用”**。</p><h4 id="学习路线图（预计耗时：1-2周）"><a href="#学习路线图（预计耗时：1-2周）" class="headerlink" title="学习路线图（预计耗时：1-2周）"></a>学习路线图（预计耗时：1-2周）</h4><h4 id="第-1-步：理解核心逻辑（1天）"><a href="#第-1-步：理解核心逻辑（1天）" class="headerlink" title="第 1 步：理解核心逻辑（1天）"></a>第 1 步：理解核心逻辑（1天）</h4><p>不要看公式，看图解。</p><ul><li><strong>核心</strong>：Diffusion 就是一个“去噪器”。给它一张全是噪点的图，它能还原出清晰的心脏图。</li><li><strong>应用</strong>：你的 3DGS 插值出来的切片，可能带有模糊或伪影（这可以被视为一种“噪声”）。你可以用训练好的 Diffusion 模型把这个“模糊切片”修成“清晰切片”。</li></ul><h4 id="第-2-步：跑通代码（3-4天）"><a href="#第-2-步：跑通代码（3-4天）" class="headerlink" title="第 2 步：跑通代码（3-4天）"></a>第 2 步：跑通代码（3-4天）</h4><p>不要自己写模型，使用 <strong>Hugging Face Diffusers</strong> 库，或者医学影像专用的 <strong>MONAI Generative Models</strong>。</p><ul><li><strong>推荐工具</strong>：MONAI (Project MONAI)。它是专门做医学影像 AI 的，里面有现成的 <code>DiffusionModelUNet</code>。</li><li><strong>任务</strong>：<ol><li>把你的 20 张 SAX 和 5 张 LAX 数据整理好（归一化到 0-1）。</li><li>用这些 2D 切片训练一个简单的 <strong>DDPM (Denoising Diffusion Probabilistic Model)</strong>。</li><li>因为你数据量小（如果是单病人数据），模型很容易过拟合，但这对你来说反而是好事（Overfitting to the patient），因为你就是想重建这个特定的病人。</li></ol></li></ul><h4 id="第-3-步：集成到-3DGS（最关键的一步）"><a href="#第-3-步：集成到-3DGS（最关键的一步）" class="headerlink" title="第 3 步：集成到 3DGS（最关键的一步）"></a>第 3 步：集成到 3DGS（最关键的一步）</h4><p>怎么把上面练好的模型加到 3DGS 里？有两种方案，推荐<strong>方案 B</strong>（更简单，易落地）。</p><ul><li><p><strong>方案 A (高难度，类似 DreamFusion&#x2F;SDS)</strong>：</p><ul><li>在 3DGS 训练 loss 里加一项梯度，这需要深入改写 PyTorch 的反向传播，坑很多，容易不收敛。</li></ul></li><li><p><strong>方案 B (低难度，伪标签法 - Pseudo Labeling)</strong>：</p><ul><li><strong>流程</strong>：<ol><li>用你现有的 Vegas&#x2F;插值方法，先生成一个粗糙的密集 Z 轴切片（比如插值出 100 张）。</li><li>把这 100 张粗糙图，扔给你刚训练好的 Diffusion 模型，运行 <strong>“Image-to-Image” (Img2Img)</strong> 模式。</li><li>Diffusion 会把粗糙图“修”得像真的 MRI。</li><li><strong>把修好的图当作 Ground Truth（真值）</strong>，再重新训练一遍 3DGS。</li></ol></li><li><strong>好处</strong>：完全解耦。你不需要改 3DGS 的底层 CUDA 代码，只需要处理图片。</li></ul></li></ul><h3 id="总结你的论文“配方”"><a href="#总结你的论文“配方”" class="headerlink" title="总结你的论文“配方”"></a>总结你的论文“配方”</h3><p>如果你觉得 Diffusion 实在太难啃，我建议你保留 <strong>长轴监督</strong>，并将重心放在 <strong>“解决呼吸运动导致的长短轴未对齐问题”</strong> 上。</p><p><strong>推荐的论文配置（如果不加 Diffusion）：</strong></p><ol><li><strong>Title</strong>: Robust 4D Cardiac Reconstruction via 3D Gaussian Splatting with <strong>Misalignment-Aware</strong> Orthogonal Views.</li><li><strong>Method</strong>:<ul><li><strong>Base</strong>: 4D Gaussian Splatting (处理时间维度).</li><li><strong>Key Module</strong>: Learnable Slice Pose (在训练中自动修正长轴切片的轻微位移).</li><li><strong>Loss</strong>: Orthogonal Consistency Loss (在长短轴交界处强制一致).</li></ul></li></ol><p><strong>推荐的论文配置（如果加 Diffusion）：</strong></p><ol><li><strong>Title</strong>: <strong>Generative</strong> 4D Cardiac MRI Reconstruction: Combining Gaussian Splatting with Diffusion Priors.</li><li><strong>Method</strong>:<ul><li>先用长轴+短轴训练粗糙 3DGS。</li><li>导出插值切片，用 Diffusion 模型进行 <strong>Inpainting&#x2F;Refinement</strong>。</li><li>将 Refine 后的数据回填，微调 3DGS。</li></ul></li></ol><p>我的建议：先做长轴监督（加上位姿修正）。如果效果已经很好（SSIM&#x2F;PSNR 提升明显），其实已经够一篇不错的会议论文了。Diffusion 可以作为锦上添花，如果时间来不及可以不加，或者作为 Future Work。</p><hr><h1 id="一些思考"><a href="#一些思考" class="headerlink" title="一些思考"></a>一些思考</h1><ol><li>首先LAX图像和SAX到底是不是完全对齐的，也就是每一帧的切片是否是同一时刻采集的，如果不是完全对齐的，就需要考虑到配准，要把SAX和LAX放到同一个空间里面来</li><li>方法的话可以设置一个3dgs的微小的位姿优化模块，让高斯核在训练几何结构的时候同时自动微调lAX切片的旋转和和平移</li><li></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>写论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vegas</title>
    <link href="/2025/11/19/vegas/"/>
    <url>/2025/11/19/vegas/</url>
    
    <content type="html"><![CDATA[<h3 id="1-核心思路：把“时间”变成“空间”-Time-as-Depth"><a href="#1-核心思路：把“时间”变成“空间”-Time-as-Depth" class="headerlink" title="1. 核心思路：把“时间”变成“空间” (Time as Depth)"></a>1. 核心思路：把“时间”变成“空间” (Time as Depth)</h3><p>普通的 3DGS 是把 $x, y, z$ 三维空间里的物体变成高斯球。<br>而 <strong>VeGaS</strong> 处理的是一段 2D 视频。视频本来是 $(x, y)$ 的图像随时间 $t$ 变化。</p><p>VeGaS 做了一个很有趣的转换：</p><ul><li>它把视频看作一个 <strong>3D 空间-时间体积 (Space-Time Volume)</strong>。</li><li><strong>X 轴 &amp; Y 轴</strong>：还是图像的宽和高。</li><li><strong>Z 轴</strong>：变成了<strong>时间 (Time)</strong>。</li></ul><p>你可以想象把视频的每一帧画面打印出来，像一摞纸一样叠在一起。这就变成了一个长方体。VeGaS 就在这个“长方体”里扔高斯球，用来拟合这摞纸上的像素颜色。</p><h3 id="2-VeGaS-解决的痛点：非线性动态-Non-linear-Dynamics"><a href="#2-VeGaS-解决的痛点：非线性动态-Non-linear-Dynamics" class="headerlink" title="2. VeGaS 解决的痛点：非线性动态 (Non-linear Dynamics)"></a>2. VeGaS 解决的痛点：非线性动态 (Non-linear Dynamics)</h3><p>如果只是简单地把视频叠成 3D 空间，用普通的 3D 高斯球去拟合，会遇到一个大问题：<strong>动作通常不是直线的。</strong></p><ul><li><strong>普通高斯球的局限：</strong> 标准的 3D 高斯球是椭球体，它的形状是线性的（直的）。</li><li><strong>视频里的问题：</strong> 比如视频里一个人在挥手，手的轨迹是<strong>弧线</strong>。如果你用一个长长的直条形椭球去代表这只手在几秒内的轨迹，它根本对不上（手是弯着动的，球是直的）。</li><li><strong>之前的笨办法：</strong> 之前的算法（如 VGR）只能把手切成无数个极短的小球，或者强行用变形场去扭，效果不好且难以编辑。</li></ul><h3 id="3-核心魔法：折叠高斯-Folded-Gaussians"><a href="#3-核心魔法：折叠高斯-Folded-Gaussians" class="headerlink" title="3. 核心魔法：折叠高斯 (Folded-Gaussians)"></a>3. 核心魔法：折叠高斯 (Folded-Gaussians)</h3><p>这是 VeGaS 这篇论文最大的创新点。</p><p>为了解决“动作是弯的，球是直的”这个问题，作者发明了一种新的数学工具——<strong>Folded-Gaussian Distribution（折叠高斯分布）</strong>。</p><ul><li><strong>原理：</strong> 这种新型高斯球不再是死板的椭球。它引入了一个多项式函数，允许高斯球在“时间轴”方向上发生<strong>非线性的弯曲</strong>。</li><li><strong>通俗理解：</strong> 想象你有一根这就好比一根直香肠（普通高斯），现在你可以把它<strong>掰弯</strong>（Folded Gaussian），让它完美贴合视频里那个挥手动作的弧线轨迹。</li><li><strong>条件概率：</strong> 当我们需要渲染某一帧（比如第 5 秒）时，VeGaS 会在这个弯曲的高斯管上“切一刀”（Conditioning），切出来的截面就是一个 2D 的高斯斑点，正好对应那一帧图像里的物体。</li></ul><h3 id="4-VeGaS-的训练与渲染过程"><a href="#4-VeGaS-的训练与渲染过程" class="headerlink" title="4. VeGaS 的训练与渲染过程"></a>4. VeGaS 的训练与渲染过程</h3><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><ol><li><strong>输入：</strong> 一段普通的 2D 视频（不需要多视角，就普通手机拍的视频）。</li><li><strong>初始化：</strong> 在这个“视频立方体”里撒入 3D 高斯球。</li><li><strong>优化：</strong><ul><li>调整这些球的位置、颜色。</li><li><strong>关键：</strong> 调整“折叠参数”，让高斯球弯曲，去追踪视频里物体的运动轨迹。</li><li>利用对比原始视频帧的 Loss 来更新参数。</li></ul></li></ol><h4 id="渲染与编辑过程"><a href="#渲染与编辑过程" class="headerlink" title="渲染与编辑过程"></a>渲染与编辑过程</h4><p>VeGaS 的主要目的不是为了“到处看”（像 3D 漫游），而是为了<strong>编辑视频</strong>。</p><ul><li><strong>视频重建：</strong> 在任意时间点 $t$ 切片，都能还原出清晰的图像。</li><li><strong>视频编辑（亮点）：</strong><ul><li>因为视频里的一个物体（比如一只猫）被表示成了一组连贯的“弯曲高斯球”。</li><li>你可以直接选中这组高斯球，进行<strong>移动、缩放、复制</strong>。</li><li><strong>效果：</strong> 你可以在视频里把这只猫变大一倍，或者把猫从左边移到右边，或者复制出两只猫。由于高斯球记录了猫随时间的所有动作，<strong>修改后的猫依然会保持原本的动作连贯性</strong>，看起来非常真实。</li></ul></li></ul><h3 id="5-总结：VeGaS-的意义"><a href="#5-总结：VeGaS-的意义" class="headerlink" title="5. 总结：VeGaS 的意义"></a>5. 总结：VeGaS 的意义</h3><p><strong>VeGaS</strong> 不是用来做 VR 里的 3D 场景漫游的（那是 4DGS 或 Dynamic 3DGS 做的事），它是用来做 <strong>AIGC 视频编辑</strong>的。</p><ul><li><strong>以前的视频编辑：</strong> 想把视频里的人P掉或移动，需要一帧一帧修（Rotoscoping），非常痛苦。</li><li><strong>VeGaS 的编辑：</strong> 把视频变成一堆“有时间属性的球”。想改哪里，直接拖动那些球，整个视频的动作就自动跟着改了。</li></ul><p><strong>一句话概括：</strong><br>VeGaS 是一种利用**“折叠高斯”<strong>技术，将 2D 视频转化为</strong>可编辑的 3D 时空表示**的技术，它让视频内容的修改变得像编辑 PPT 里的图片一样简单。</p><p>这是一个非常敏锐的发现！你把 <strong>MRI（医学图像）</strong> 和 <strong>Video（视频）</strong> 联系起来是非常准确的直觉，因为从数学和数据结构上看，它们本质上是一回事。</p><p>在 MedGS（或者类似的医学 3DGS 论文）中，借鉴 <strong>VeGaS</strong>（或 Video-based 3DGS）的思路是非常自然的。</p><p>让我们来拆解一下 MedGS 是如何“魔改” VeGaS 的原理，把 20 张 MRI 切片变成一个连续的 3D 器官模型的。</p><h3 id="1-核心映射：时间-t-vs-空间-z"><a href="#1-核心映射：时间-t-vs-空间-z" class="headerlink" title="1. 核心映射：时间 $t$ vs. 空间 $z$"></a>1. 核心映射：时间 $t$ vs. 空间 $z$</h3><p>VeGaS 的核心是处理 $(x, y, t)$，而 MRI 数据是 $(x, y, z)$。</p><ul><li><strong>在 VeGaS 中：</strong> 第 3 维度是<strong>时间</strong>。第 1 帧和第 2 帧之间，代表物体“动”了一点点。</li><li><strong>在 MedGS 中：</strong> 第 3 维度是<strong>深度（层）</strong>。第 1 张切片和第 2 张切片之间，代表人体组织结构“变”了一点点。</li></ul><p><strong>魔改的第一步</strong>就是直接把 MRI 的第 $i$ 张切片，当成视频的第 $i$ 帧喂给网络。网络以为它在学一个“变形的动画”，其实它在学一个“静态的 3D 结构”。</p><h3 id="2-渲染方式的魔改：从“拍照”变成“切片”"><a href="#2-渲染方式的魔改：从“拍照”变成“切片”" class="headerlink" title="2. 渲染方式的魔改：从“拍照”变成“切片”"></a>2. 渲染方式的魔改：从“拍照”变成“切片”</h3><p>这是最关键的区别。普通的 3DGS（包括 VeGaS）是模拟<strong>摄像机（Camera）</strong>，有近大远小的透视效果。但 MRI 不需要透视。</p><p>MedGS 对渲染管线做了如下修改：</p><ul><li><strong>原版 VeGaS&#x2F;3DGS：</strong><ul><li>我在 3D 空间放一个摄像机。</li><li>把高斯球投影到屏幕上（Perspective Projection）。</li><li>计算颜色叠加。</li></ul></li><li><strong>魔改后的 MedGS：</strong><ul><li><strong>正交投影 (Orthographic Projection)：</strong> 取消“近大远小”，模拟医学扫描仪的射线平行穿过。</li><li><strong>条件切片 (Conditional Slicing)：</strong><br>当训练第 5 张 PNG（假设它对应 $z&#x3D;10mm$ 处）时，算法<strong>只激活</strong>和渲染 z 轴坐标在 $10mm$ 附近的高斯球。<br>它就像一把<strong>数字手术刀</strong>，只横切这一层，计算这一层截面的颜色，然后跟第 5 张 PNG 去算 Loss。</li></ul></li></ul><h3 id="3-从“运动轨迹”到“组织连续性”"><a href="#3-从“运动轨迹”到“组织连续性”" class="headerlink" title="3. 从“运动轨迹”到“组织连续性”"></a>3. 从“运动轨迹”到“组织连续性”</h3><p>你提到只有 20 张 PNG，这在医学上属于<strong>稀疏采样 (Sparse Sampling)</strong>（通常 MRI 可能需要上百张才清晰）。如果直接堆叠，层与层之间会有很大的缝隙。</p><p>利用 VeGaS 的逻辑，MedGS 实现了<strong>超分辨率（Super-resolution）</strong>：</p><ul><li><strong>VeGaS 的逻辑：</strong> 视频只有 24 帧，但我想要 60 帧。利用高斯球的变形能力，我可以算出第 1.5 帧长什么样（插帧）。</li><li><strong>MedGS 的逻辑：</strong> MRI 只有 20 层（z&#x3D;1, z&#x3D;2…），层间距很大。利用高斯球在空间中的连续分布，我可以渲染出 <strong>z&#x3D;1.5</strong> 处的切片。</li><li><strong>结果：</strong> 哪怕原始数据像“百叶窗”一样有缝隙，训练好的 MedGS 模型能生成一个像“果冻”一样内部完全连续的 3D 器官。医生可以随意查看任意深度的切面，而不仅限于那 20 张原图。</li></ul><h3 id="4-颜色的重新定义"><a href="#4-颜色的重新定义" class="headerlink" title="4. 颜色的重新定义"></a>4. 颜色的重新定义</h3><ul><li><strong>VeGaS：</strong> 优化的是 RGB 颜色（红绿蓝）。</li><li><strong>MedGS：</strong> 优化的是<strong>灰度值</strong>或<strong>辐射密度</strong>。<br>医学图像（如 CT&#x2F;MRI）的像素值不仅是颜色，还代表物理意义（比如 Hounsfield Unit，代表组织密度）。MedGS 会把高斯球的属性从“发光颜色”魔改为“组织密度&#x2F;信号强度”。</li></ul><h3 id="总结：MedGS-到底做了什么？"><a href="#总结：MedGS-到底做了什么？" class="headerlink" title="总结：MedGS 到底做了什么？"></a>总结：MedGS 到底做了什么？</h3><p>它把那 20 张 PNG 不当作“照片”，而是当作 <strong>20 个路标（Checkpoints）</strong>。</p><ol><li><strong>初始化：</strong> 在 3D 空间撒一把高斯球。</li><li><strong>训练：</strong><ul><li>切到 $z&#x3D;1$ 的位置，渲染出一张图，跟第 1 张 PNG 比对，调整高斯球让它们长得像肝脏&#x2F;肿瘤。</li><li>切到 $z&#x3D;2$ 的位置，跟第 2 张 PNG 比对…</li></ul></li><li><strong>魔改点（VeGaS 思想）：</strong><br>它利用高斯球的体积特性，<strong>自动脑补</strong>了第 1 张和第 2 张图片之间没拍到的那些组织结构（就像 VeGaS 脑补帧与帧之间的动作一样）。</li></ol><p>最终，你得到的不只是 20 张图片，而是一个<strong>可任意旋转、任意切片、分辨率无限放大</strong>的 3D 数字人体模型。这就是 3DGS 技术在医学重建上的核心意义。</p><hr><p>这是一个非常棒的质疑！你的直觉很敏锐：<strong>“凭什么3DGS在没数据的空白区域（两张切片之间）瞎猜，会比数学上老实巴交的线性插值（Linear Interpolation）更好？”</strong></p><p>事实上，在早期的NeRF和3DGS研究中，大家也有这个怀疑。但经过实验证明，在医学图像（特别是像MRI&#x2F;CT这种层间距较大的情况）重建上，<strong>3DGS（或基于隐式神经表示的方法）通常完爆线性插值</strong>。</p><p>核心原因在于：<strong>线性插值不懂“结构”，而3DGS自带“几何先验”。</strong></p><p>我们可以通过三个具体的维度来对比：<strong>“斜向结构”、“边缘锐度”和“伪影问题”</strong>。</p><hr><h3 id="1-“斜向结构”难题（最直观的差异）"><a href="#1-“斜向结构”难题（最直观的差异）" class="headerlink" title="1. “斜向结构”难题（最直观的差异）"></a>1. “斜向结构”难题（最直观的差异）</h3><p>假设有一个<strong>血管</strong>，它不是垂直生长的，而是<strong>斜着</strong>穿过人体。</p><ul><li><p><strong>MRI切片情况：</strong></p><ul><li>切片 A（z&#x3D;0）：血管在坐标 (10, 10)。</li><li>切片 B（z&#x3D;1）：血管在坐标 (12, 12)。</li><li><strong>真实情况</strong>：在 z&#x3D;0.5 的中间位置，血管应该在 (11, 11)。</li></ul></li><li><p><strong>线性插值 (Linear Interpolation) 的做法：</strong></p><ul><li>它只会在像素层面对齐。它会把切片A的(10,10)和切片B的(10,10)混合，把切片A的(12,12)和切片B的(12,12)混合。</li><li><strong>结果：</strong> 在 z&#x3D;0.5 处，你会看到<strong>两个半透明的模糊影子</strong>（Ghosting），一个在(10,10)，一个在(12,12)，而真正的中心(11,11)反而是空的或者灰蒙蒙的。</li><li><strong>后果：</strong> 血管断了，变成了两个虚影。</li></ul></li><li><p><strong>3DGS 的做法：</strong></p><ul><li>高斯球是 3D 的椭球体，它可以<strong>旋转</strong>。</li><li>为了同时拟合切片A的(10,10)和切片B的(12,12)，优化算法会自动把一个长条形的高斯球<strong>斜着摆放</strong>。</li><li><strong>结果：</strong> 在 z&#x3D;0.5 处，如果你去切这个高斯球，截面正好就在 (11,11)。</li><li><strong>优势：</strong> 它保留了血管的<strong>连续性和拓扑结构</strong>。它“猜”到了这两点之间应该连着一根管子，而不是两个孤立的点。</li></ul></li></ul><h3 id="2-边缘锐度-Sharpness-vs-模糊"><a href="#2-边缘锐度-Sharpness-vs-模糊" class="headerlink" title="2. 边缘锐度 (Sharpness) vs. 模糊"></a>2. 边缘锐度 (Sharpness) vs. 模糊</h3><ul><li><p><strong>线性插值：</strong></p><ul><li>本质上是一个<strong>低通滤波器</strong>。当你对两张图片进行加权平均时，图像的高频信息（锐利的边缘、纹理）会被抹平。</li><li>重建出来的 3D 模型，侧面看会像是一层层堆叠的阶梯（Staircase artifacts），或者整体像被磨皮了一样糊。</li></ul></li><li><p><strong>3DGS：</strong></p><ul><li>高斯函数本身虽然是平滑的，但多个高斯球叠加可以通过调整 $\alpha$（不透明度）和 Scale（大小）来拟合非常锐利的边缘（Step Function）。</li><li>它不是在混合像素，而是在<strong>拟合边界</strong>。即使在两层切片之间，高斯球定义的边界依然是清晰确定的。</li></ul></li></ul><h3 id="3-3DGS-的“脑补”逻辑：几何先验-Geometric-Priors"><a href="#3-3DGS-的“脑补”逻辑：几何先验-Geometric-Priors" class="headerlink" title="3. 3DGS 的“脑补”逻辑：几何先验 (Geometric Priors)"></a>3. 3DGS 的“脑补”逻辑：几何先验 (Geometric Priors)</h3><p>你担心的“3DGS不适合对空白区域插值”，其实是因为你把它看作是“填空”。但实际上，3DGS 把它看作是**“放置积木”**。</p><ul><li><strong>生物学特性：</strong> 人体组织（器官、肿瘤、血管）在物理上通常是<strong>连续的团块</strong>或<strong>管道</strong>。</li><li><strong>高斯球特性：</strong> 高斯球正好就是<strong>团块状</strong>的。</li><li><strong>原理：</strong> 当你强迫一堆高斯球去适配 z&#x3D;0 和 z&#x3D;1 的切片时，由于高斯球本身有体积（Scale），它的“肚子”填满了 z&#x3D;0 和 z&#x3D;1 之间的空隙。</li><li>这相当于给插值过程加了一个约束：<strong>“中间补出来的东西，必须看起来像是一团连续的物质，而不能是杂乱的噪点。”</strong></li></ul><h3 id="总结：为什么-3DGS-更强？"><a href="#总结：为什么-3DGS-更强？" class="headerlink" title="总结：为什么 3DGS 更强？"></a>总结：为什么 3DGS 更强？</h3><table><thead><tr><th align="left">对比维度</th><th align="left">线性插值 (Linear Interpolation)</th><th align="left">3DGS &#x2F; MedGS</th></tr></thead><tbody><tr><td align="left"><strong>处理逻辑</strong></td><td align="left">纯数学计算，像素对像素混合</td><td align="left">几何拟合，用 3D 形状去逼近数据</td></tr><tr><td align="left"><strong>斜向物体</strong></td><td align="left">产生重影 (Ghosting)，结构断裂</td><td align="left"><strong>自动对齐</strong>，保持管状&#x2F;块状连续性</td></tr><tr><td align="left"><strong>层间空隙</strong></td><td align="left">模糊过渡，丢失细节</td><td align="left"><strong>利用椭球体积填充</strong>，保持边缘清晰</td></tr><tr><td align="left"><strong>数据依赖</strong></td><td align="left">极度依赖采样率，层距大就完蛋</td><td align="left">对稀疏数据鲁棒性更强（能脑补）</td></tr></tbody></table><p><strong>结论：</strong><br>如果你的 MRI 切片非常密集（比如 z 轴分辨率极高），线性插值够快也够用。<br>但正如你所说，只有 <strong>20 张切片</strong>（稀疏数据），线性插值会导致严重的<strong>层间断裂</strong>和<strong>阶梯效应</strong>。这时候，3DGS 利用其<strong>几何连续性</strong>的特性，能“猜”出比线性插值更符合人体生理结构的中间层。</p><p>它不是在瞎猜，它是假设“人体是连续的 3D 实体”来进行拟合，这在医学上是一个非常合理的假设。</p>]]></content>
    
    
    
    <tags>
      
      <tag>vegas</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3dgs的技术原理</title>
    <link href="/2025/11/19/3dgs%E9%9A%8F%E6%83%B3/"/>
    <url>/2025/11/19/3dgs%E9%9A%8F%E6%83%B3/</url>
    
    <content type="html"><![CDATA[<p><strong>3D Gaussian Splatting (3DGS)</strong> 是近年来计算机图形学和计算机视觉领域的一项突破性技术。它结合了显式几何表示（点云&#x2F;粒子）和体积渲染的优点，实现了<strong>实时的渲染速度</strong>和<strong>照片级的重建质量</strong>。</p><p>下面我将分两部分为你详细拆解：3DGS的<strong>训练与渲染流程</strong>，以及<strong>3D重建的深层意义</strong>。</p><hr><h3 id="第一部分：3DGS-的技术原理"><a href="#第一部分：3DGS-的技术原理" class="headerlink" title="第一部分：3DGS 的技术原理"></a>第一部分：3DGS 的技术原理</h3><p>简单来说，3DGS 不使用网格（Mesh）或神经网络（如 NeRF 中的 MLP）来表示物体，而是使用成千上万个<strong>3D 高斯椭球（3D Gaussians）</strong>。你可以把它们想象成无数个<strong>半透明的发光小云团</strong>，它们叠加在一起就组成了物体。</p><h4 id="1-渲染过程-Rendering-Process-前向传播"><a href="#1-渲染过程-Rendering-Process-前向传播" class="headerlink" title="1. 渲染过程 (Rendering Process) - 前向传播"></a>1. 渲染过程 (Rendering Process) - 前向传播</h4><p>这是展示结果的过程，也是训练中计算 Loss 的基础。3DGS 的渲染速度之所以极快（100+ FPS），是因为它采用了类似传统图形学的**光栅化（Rasterization）**管线。</p><ul><li><strong>输入：</strong> 一组 3D 高斯球。每个球包含属性：<ul><li><strong>位置 (Position):</strong> $x, y, z$</li><li><strong>形状 (Covariance):</strong> 由缩放 (Scale) 和旋转 (Rotation&#x2F;Quaternion) 决定。</li><li><strong>颜色 (Color):</strong> 使用球谐函数 (Spherical Harmonics) 表示，支持随视角变化的反射光泽。</li><li><strong>不透明度 (Opacity):</strong> $\alpha$，决定这个球有多“实”。</li></ul></li><li><strong>步骤 1：投影 (Projection)</strong><ul><li>将 3D 空间中的椭球投影到 2D 屏幕（摄像机平面）。</li><li>这个过程就像把一个气球压扁在纸上，3D 椭球变成了 2D 平面上的高斯分布（类似于一个模糊的圆斑）。</li></ul></li><li><strong>步骤 2：排序 (Sorting)</strong><ul><li><strong>关键步骤</strong>：将屏幕上所有的 2D 高斯斑点按照<strong>深度</strong>（离摄像机的距离）进行排序。通常是从远到近（Back-to-Front）。</li><li>3DGS 使用了非常高效的 GPU 基数排序（Radix Sort）。</li></ul></li><li><strong>步骤 3：基于图块的光栅化 (Tile-based Rasterization)</strong><ul><li>为了并行加速，屏幕被划分成 $16 \times 16$ 的小方块（Tiles）。</li><li>对每个像素，按顺序叠加高斯斑点的颜色。使用<strong>Alpha Blending</strong> 公式：<br>$$C &#x3D; \sum_{i} c_i \alpha_i T_i$$<br>（$T_i$ 代表前面所有层剩余的透明度，即“还没被挡住的光”）。</li><li>当不透明度累积到饱和（完全不透光）时，该像素停止计算，节省资源。</li></ul></li></ul><h4 id="2-训练过程-Training-Process-优化与自适应"><a href="#2-训练过程-Training-Process-优化与自适应" class="headerlink" title="2. 训练过程 (Training Process) - 优化与自适应"></a>2. 训练过程 (Training Process) - 优化与自适应</h4><p>训练的目标是：调整这几百万个高斯球的属性，使得它们渲染出来的图和真实照片一模一样。</p><ul><li><strong>初始化 (Initialization):</strong><ul><li>通常从<strong>稀疏点云</strong>（SfM，如 COLMAP 生成的点）开始。每个点初始化为一个小的 3D 高斯球。</li></ul></li><li><strong>迭代优化循环 (Optimization Loop):</strong><ol><li><strong>渲染</strong>：从当前视角渲染图像。</li><li><strong>计算 Loss</strong>：对比渲染图和真实照片（L1 Loss + D-SSIM），计算误差。</li><li><strong>反向传播 (Backpropagation)</strong>：计算梯度，更新每个高斯球的位置、形状、颜色和不透明度。</li></ol></li><li><strong>自适应密度控制 (Adaptive Density Control) - 3DGS 的核心魔法:</strong><br>单纯的梯度下降是不够的，3DGS 会动态地<strong>增加</strong>或<strong>删除</strong>高斯球：<ul><li><strong>克隆 (Clone):</strong> 如果一个高斯球很小，但梯度很大（说明这里细节不够），就把它复制一份，填补空缺（用于填充细节）。</li><li><strong>分裂 (Split):</strong> 如果一个高斯球很大，且梯度很大（说明它试图覆盖形状复杂的区域，导致甚至出现了伪影），就把它切分成两个小球（用于精细化几何）。</li><li><strong>剪枝 (Prune):</strong> 如果一个高斯球的不透明度 $\alpha$ 变得非常低（几乎透明），或者形状变得极其巨大&#x2F;极其细长（异常值），直接删除。</li></ul></li><li><strong>结果：</strong> 经过几万次迭代，从最初稀疏的点云，演变成数百万个精细分布的高斯球，完美拟合场景。</li></ul><hr><h3 id="第二部分：如何理解-3D-重建的意义"><a href="#第二部分：如何理解-3D-重建的意义" class="headerlink" title="第二部分：如何理解 3D 重建的意义"></a>第二部分：如何理解 3D 重建的意义</h3><p>3D 重建（3D Reconstruction）不仅仅是“把照片变成模型”，它是<strong>连接物理世界与数字世界的桥梁</strong>。我们可以从以下四个维度来理解它的意义：</p><h4 id="1-数字化存档与文化传承-Preservation"><a href="#1-数字化存档与文化传承-Preservation" class="headerlink" title="1. 数字化存档与文化传承 (Preservation)"></a>1. 数字化存档与文化传承 (Preservation)</h4><ul><li><strong>超越照片的维度：</strong> 照片是二维的切片，丢失了深度和空间感。3D 重建是对物理空间的完整“克隆”。</li><li><strong>应用：</strong> 巴黎圣母院大火后，正是依靠之前的激光扫描和 3D 重建数据，修复工作才有了精确的蓝图。文物的数字化让后人即使在实物损毁后，也能在数字世界永恒地观察其细节。</li></ul><h4 id="2-沉浸式交互的基石-Interaction-Spatial-Computing"><a href="#2-沉浸式交互的基石-Interaction-Spatial-Computing" class="headerlink" title="2. 沉浸式交互的基石 (Interaction &amp; Spatial Computing)"></a>2. 沉浸式交互的基石 (Interaction &amp; Spatial Computing)</h4><ul><li><strong>6DoF (六自由度) 体验：</strong> 看视频是被动的（摄像机怎么动你就怎么看）。但有了 3D 重建，用户可以在场景中自由行走（VR&#x2F;AR）。</li><li><strong>空间计算时代：</strong> 随着 Apple Vision Pro 等设备的出现，屏幕不再局限于显示器，而是整个空间。3DGS 这种技术让<strong>把现实世界搬进头显</strong>成为可能，实现了远程旅游、远程看房的真实感（Telepresence）。</li></ul><h4 id="3-机器感知与人工智能-AI-Robotics"><a href="#3-机器感知与人工智能-AI-Robotics" class="headerlink" title="3. 机器感知与人工智能 (AI &amp; Robotics)"></a>3. 机器感知与人工智能 (AI &amp; Robotics)</h4><ul><li><strong>机器的眼睛：</strong> 自动驾驶汽车和机器人不仅需要看到“图片”，更需要理解“空间”。</li><li><strong>SLAM 与 导航：</strong> 3D 重建帮助机器人理解“我在哪里”、“前面有什么障碍物”、“这个物体的形状是什么”。</li><li><strong>具身智能 (Embodied AI)：</strong> 如果我们要训练一个机器人去拿杯子，它必须在一个物理准确的 3D 环境中模拟训练。3DGS 可以快速构建这种高保真的模拟环境。</li></ul><h4 id="4-内容创作的民主化-Democratization-of-Creation"><a href="#4-内容创作的民主化-Democratization-of-Creation" class="headerlink" title="4. 内容创作的民主化 (Democratization of Creation)"></a>4. 内容创作的民主化 (Democratization of Creation)</h4><ul><li><strong>降低门槛：</strong> 以前做 3D 场景需要专业的建模师用 Maya&#x2F;Blender 耗时数周。</li><li><strong>AIGC 3D：</strong> 现在的技术（如 3DGS）允许普通人用手机拍一段视频，几分钟内就生成电影级的 3D 场景。这极大地解放了游戏开发、电影特效（VFX）和元宇宙内容的生产力。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>3DGS</strong> 是一种<strong>显式、高效、可微</strong>的渲染技术，它通过“泼溅”数百万个微小的椭球来欺骗我们的眼睛，让我们看到连续的物体。</p><p>而 <strong>3D 重建</strong> 的意义在于**“空间化”**信息。它将人类对世界的感知从 2D 图像升级为 3D 空间，不仅让人类能更真实地回溯记忆，也让 AI 能够真正地理解和操作物理世界。</p>]]></content>
    
    
    
    <tags>
      
      <tag>3dgs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的第一篇文章</title>
    <link href="/2025/11/19/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/"/>
    <url>/2025/11/19/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>荒废了好久的博客，最近才开始重新写。</p>]]></content>
    
    
    
    <tags>
      
      <tag>hexo</tag>
      
      <tag>next</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2025/11/19/hello-world/"/>
    <url>/2025/11/19/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
